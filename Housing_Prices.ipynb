{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Housing_Prices.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxElm0JuxZplJMwvWO1vCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsshih/Kaggle_Housing_Prices/blob/main/Housing_Prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJr1PoaVIS3M"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtFDPnlQIYNf"
      },
      "source": [
        "# Read the housing prices data set\n",
        "df_train = pd.read_csv('train.csv')\n",
        "#df_test = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "#Apply log transformation to make the 'SalePrice' distribution normal\n",
        "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymMzIvGIr5M"
      },
      "source": [
        "total = df_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
        "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bramRHpCIuQL"
      },
      "source": [
        "# Delete outliars \n",
        "df_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
        "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
        "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojsY_snsIxao"
      },
      "source": [
        "#Find columns with highest correlation with \"Sales Price\"\n",
        "corrmat = df_train.corr()\n",
        "k = 15 # number of variables to find (+1 to include 'Sales Price')\n",
        "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
        "\n",
        "target = df_train['SalePrice']\n",
        "features = df_train[cols[1:]]\n",
        "#print(features.columns)   # Print columns in selected features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ6yl2vUIzfZ"
      },
      "source": [
        "#Split data in the train and test sample\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz5B0mNKI2Mj"
      },
      "source": [
        "## Try simple linear regression\n",
        "#from sklearn import linear_model\n",
        "#reg = linear_model.LinearRegression()\n",
        "#reg.fit(feature_train, target_train)\n",
        "#print(reg.coef_)\n",
        "#print(reg.intercept_)\n",
        "#print(reg.score(feature_train, target_train))\n",
        "#print(reg.score(feature_test, target_test))\n",
        "#predict = pd.DataFrame(reg.predict(feature_test),columns=['Prediction'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F32qQc5OI5eP"
      },
      "source": [
        "## Try KFold cross valication with linear regressgion\n",
        "from sklearn import linear_model\n",
        "scores = []\n",
        "from sklearn.model_selection import KFold\n",
        "reg = linear_model.LinearRegression()\n",
        "cv = KFold(n_splits=10, random_state=None, shuffle=True)\n",
        "for train_index, test_index in cv.split(features):\n",
        "    # Use index.intersection to avoid having null values due to non-matching index\n",
        "    feature_train, feature_test, target_train, target_test = \\\n",
        "    features.loc[features.index.intersection(train_index)], \\\n",
        "    features.loc[features.index.intersection(test_index)], \\\n",
        "    target.loc[features.index.intersection(train_index)], \\\n",
        "    target.loc[features.index.intersection(test_index)]\n",
        "    reg.fit(feature_train, target_train)\n",
        "    scores.append(reg.score(feature_test, target_test))\n",
        "predict = pd.DataFrame(reg.predict(feature_test),columns=['Prediction'])\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1whgIuFJIbO"
      },
      "source": [
        "## Try Support Vector Regression\n",
        "#from sklearn.svm import SVR\n",
        "#svr_rbf = SVR(kernel='linear')\n",
        "#svr_rbf.fit(feature_train, target_train)\n",
        "#predict = pd.DataFrame(svr_rbf.predict(feature_test),columns=['Prediction'])\n",
        "#print(svr_rbf.score(feature_test, target_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNX39HEzJIye"
      },
      "source": [
        "# Plot predict vs. test\n",
        "plt.scatter(np.exp(predict),np.exp(target_test))\n",
        "plt.xlim(0,800000)\n",
        "plt.ylim(0,800000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euXawxBUJNMA"
      },
      "source": [
        "# Plot predict and test vs. 'GrLivArea'\n",
        "plt.scatter(feature_test['GrLivArea'], np.exp(target_test),  color='black')\n",
        "plt.scatter(feature_test['GrLivArea'], np.exp(predict), color='blue')\n",
        "plt.ylim(0,800000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}